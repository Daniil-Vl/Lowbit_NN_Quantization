{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "569ef9bc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-11T15:03:40.037275Z",
     "iopub.status.busy": "2022-12-11T15:03:40.036473Z",
     "iopub.status.idle": "2022-12-11T15:03:40.048614Z",
     "shell.execute_reply": "2022-12-11T15:03:40.047762Z"
    },
    "papermill": {
     "duration": 0.021728,
     "end_time": "2022-12-11T15:03:40.050678",
     "exception": false,
     "start_time": "2022-12-11T15:03:40.028950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf86bbd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:03:40.061591Z",
     "iopub.status.busy": "2022-12-11T15:03:40.060746Z",
     "iopub.status.idle": "2022-12-11T15:03:43.740998Z",
     "shell.execute_reply": "2022-12-11T15:03:43.740033Z"
    },
    "papermill": {
     "duration": 3.688345,
     "end_time": "2022-12-11T15:03:43.743702",
     "exception": false,
     "start_time": "2022-12-11T15:03:40.055357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db01014e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:03:43.754660Z",
     "iopub.status.busy": "2022-12-11T15:03:43.754171Z",
     "iopub.status.idle": "2022-12-11T15:03:43.887659Z",
     "shell.execute_reply": "2022-12-11T15:03:43.886623Z"
    },
    "papermill": {
     "duration": 0.142024,
     "end_time": "2022-12-11T15:03:43.890598",
     "exception": false,
     "start_time": "2022-12-11T15:03:43.748574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25465d54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:03:43.904305Z",
     "iopub.status.busy": "2022-12-11T15:03:43.903939Z",
     "iopub.status.idle": "2022-12-11T15:03:43.908133Z",
     "shell.execute_reply": "2022-12-11T15:03:43.907111Z"
    },
    "papermill": {
     "duration": 0.013458,
     "end_time": "2022-12-11T15:03:43.910372",
     "exception": false,
     "start_time": "2022-12-11T15:03:43.896914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa3fdf69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:03:43.921413Z",
     "iopub.status.busy": "2022-12-11T15:03:43.920855Z",
     "iopub.status.idle": "2022-12-11T15:04:08.268564Z",
     "shell.execute_reply": "2022-12-11T15:04:08.267228Z"
    },
    "papermill": {
     "duration": 24.360596,
     "end_time": "2022-12-11T15:04:08.275758",
     "exception": false,
     "start_time": "2022-12-11T15:03:43.915162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip to ./data/EMNIST/raw/gzip.zip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534fb54fb37b4e4caa56d2f6b374de23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/561753746 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/EMNIST/raw/gzip.zip to ./data/EMNIST/raw\n"
     ]
    }
   ],
   "source": [
    "transformer = transforms.Compose(transforms=[\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5), std=(0.5))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.EMNIST(root=\"./data\", split='mnist', train=True, download=True, transform=transformer)\n",
    "trainloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "test_dataset = torchvision.datasets.EMNIST(root=\"./data\", split='mnist', train=False, download=True, transform=transformer)\n",
    "testloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae2d07f",
   "metadata": {
    "papermill": {
     "duration": 0.008592,
     "end_time": "2022-12-11T15:04:08.294624",
     "exception": false,
     "start_time": "2022-12-11T15:04:08.286032",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a94645c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:04:08.320703Z",
     "iopub.status.busy": "2022-12-11T15:04:08.320307Z",
     "iopub.status.idle": "2022-12-11T15:04:08.342318Z",
     "shell.execute_reply": "2022-12-11T15:04:08.341303Z"
    },
    "papermill": {
     "duration": 0.037805,
     "end_time": "2022-12-11T15:04:08.344914",
     "exception": false,
     "start_time": "2022-12-11T15:04:08.307109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, trainloader, number_of_epochs=10, device='cpu'):\n",
    "    steps_per_epoch = len(trainloader)\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(number_of_epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for (inputs, labels) in trainloader:\n",
    "            model.to(device)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # backward + optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'[{epoch + 1}] loss: {running_loss / steps_per_epoch:.3f}')\n",
    "\n",
    "    print('Finished training')\n",
    "\n",
    "\n",
    "def test_model(model, dataloader):\n",
    "    n_correct = 0\n",
    "    n_total = 0\n",
    "\n",
    "    model.to('cpu')\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (images, labels) in dataloader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            n_total += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            result = n_correct / n_total * 100\n",
    "\n",
    "    print(f\"Accuracy on test set: {result:.1f}%\")\n",
    "\n",
    "\n",
    "def model_size(model):\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "    size_all_kb = (param_size + buffer_size) / 1024\n",
    "    return 'model size: {:.3f}KB'.format(size_all_kb)\n",
    "\n",
    "def make_prediction(model, x):\n",
    "    x = torch.unsqueeze(x, 0)\n",
    "    x = torch.unsqueeze(x, 0)\n",
    "    \n",
    "    model.to('cpu')\n",
    "    model.eval()\n",
    "    \n",
    "    pred = model(x)\n",
    "    _, pred = torch.max(pred, 1)\n",
    "    \n",
    "    return int(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fffbab4",
   "metadata": {
    "papermill": {
     "duration": 0.008084,
     "end_time": "2022-12-11T15:04:08.363534",
     "exception": false,
     "start_time": "2022-12-11T15:04:08.355450",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7222a761",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:04:08.381594Z",
     "iopub.status.busy": "2022-12-11T15:04:08.381260Z",
     "iopub.status.idle": "2022-12-11T15:04:12.919894Z",
     "shell.execute_reply": "2022-12-11T15:04:12.918871Z"
    },
    "papermill": {
     "duration": 4.550418,
     "end_time": "2022-12-11T15:04:12.922324",
     "exception": false,
     "start_time": "2022-12-11T15:04:08.371906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    # in_channels = 1, because nn working with grayscale images\n",
    "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=256, kernel_size=3)\n",
    "    self.conv2 = nn.Conv2d(in_channels=256, out_channels=64, kernel_size=3) \n",
    "    # out_channels = number of filters\n",
    "    \n",
    "    self.relu = nn.ReLU()\n",
    "    self.relu1 = nn.ReLU()\n",
    "    self.relu2 = nn.ReLU()\n",
    "    \n",
    "    # in_features = conv2.out_channels * 5 * 5\n",
    "    # in_features = 64 * 5 * 5 = 1600\n",
    "    self.linear1 = nn.Linear(in_features=64*5*5, out_features = 500) \n",
    "    self.linear2 = nn.Linear(in_features=500, out_features = 250)\n",
    "    self.linear3 = nn.Linear(in_features=250, out_features=10) \n",
    "    # out_features = number of classes\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    x = self.relu1(self.conv1(x))\n",
    "    x = self.pool(x)\n",
    "\n",
    "    x = self.relu2(self.conv2(x))\n",
    "    x = self.pool(x)\n",
    "\n",
    "    x = torch.flatten(x, 1) \n",
    "    x = self.relu(self.linear1(x))\n",
    "    x = self.relu(self.linear2(x))\n",
    "    x = self.linear3(x)\n",
    "    return x\n",
    "    \n",
    "model = ConvNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebacf326",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:04:12.935434Z",
     "iopub.status.busy": "2022-12-11T15:04:12.934711Z",
     "iopub.status.idle": "2022-12-11T15:07:55.069735Z",
     "shell.execute_reply": "2022-12-11T15:07:55.067960Z"
    },
    "papermill": {
     "duration": 222.144841,
     "end_time": "2022-12-11T15:07:55.072855",
     "exception": false,
     "start_time": "2022-12-11T15:04:12.928014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 0.102\n",
      "[2] loss: 0.042\n",
      "[3] loss: 0.031\n",
      "[4] loss: 0.025\n",
      "[5] loss: 0.020\n",
      "[6] loss: 0.015\n",
      "[7] loss: 0.013\n",
      "[8] loss: 0.011\n",
      "[9] loss: 0.009\n",
      "[10] loss: 0.010\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    model=model,\n",
    "    criterion = nn.CrossEntropyLoss(),\n",
    "    optimizer=optim.Adam(params=model.parameters(), lr=0.001),\n",
    "    trainloader=trainloader,\n",
    "    number_of_epochs=10,\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f92ebce3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:07:55.085824Z",
     "iopub.status.busy": "2022-12-11T15:07:55.085484Z",
     "iopub.status.idle": "2022-12-11T15:08:16.487618Z",
     "shell.execute_reply": "2022-12-11T15:08:16.486380Z"
    },
    "papermill": {
     "duration": 21.411323,
     "end_time": "2022-12-11T15:08:16.490031",
     "exception": false,
     "start_time": "2022-12-11T15:07:55.078708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 99.1%\n"
     ]
    }
   ],
   "source": [
    "test_model(\n",
    "    model=model, \n",
    "    dataloader=testloader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6351dcf",
   "metadata": {
    "papermill": {
     "duration": 0.005595,
     "end_time": "2022-12-11T15:08:16.501615",
     "exception": false,
     "start_time": "2022-12-11T15:08:16.496020",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25cc92f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:08:16.514401Z",
     "iopub.status.busy": "2022-12-11T15:08:16.514059Z",
     "iopub.status.idle": "2022-12-11T15:08:16.586884Z",
     "shell.execute_reply": "2022-12-11T15:08:16.585472Z"
    },
    "papermill": {
     "duration": 0.081849,
     "end_time": "2022-12-11T15:08:16.588953",
     "exception": false,
     "start_time": "2022-12-11T15:08:16.507104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/ao/quantization/observer.py:179: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  reduce_range will be deprecated in a future release of PyTorch.\"\n"
     ]
    }
   ],
   "source": [
    "class QAT_ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=256, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=256, out_channels=64, kernel_size=3)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # in_features = 64 * 5 * 5 = 1600\n",
    "        self.linear1 = nn.Linear(in_features=64*5*5, out_features = 500) \n",
    "        self.linear2 = nn.Linear(in_features=500, out_features = 250)\n",
    "        self.linear3 = nn.Linear(in_features=250, out_features=10) \n",
    "        # out_features = number of classes\n",
    "\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.quant(x)\n",
    "        \n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.relu2(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        \n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# create a model instance\n",
    "model_fp32 = QAT_ConvNet().to(device)\n",
    "\n",
    "# model must be set to eval for fusion to work\n",
    "model_fp32.eval()\n",
    "\n",
    "# attach a global qconfig, which contains information about what kind\n",
    "# of observers to attach. Use 'fbgemm' for server inference and\n",
    "# 'qnnpack' for mobile inference. Other quantization configurations such\n",
    "# as selecting symmetric or assymetric quantization and MinMax or L2Norm\n",
    "# calibration techniques can be specified here.\n",
    "model_fp32.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
    "\n",
    "# fuse the activations to preceding layers, where applicable\n",
    "# this needs to be done manually depending on the model architecture\n",
    "model_fp32_fused = torch.quantization.fuse_modules(\n",
    "    model_fp32, [['conv1', 'relu1']])\n",
    "model_fp32_fused = torch.quantization.fuse_modules(\n",
    "    model_fp32_fused, [['conv2', 'relu2']])\n",
    "\n",
    "\n",
    "# Prepare the model for QAT. This inserts observers and fake_quants in\n",
    "# the model needs to be set to train for QAT logic to work\n",
    "# the model that will observe weight and activation tensors during calibration.\n",
    "model_fp32_prepared = torch.quantization.prepare_qat(model_fp32_fused.train())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14c3cfdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:08:16.602104Z",
     "iopub.status.busy": "2022-12-11T15:08:16.601450Z",
     "iopub.status.idle": "2022-12-11T15:12:30.599332Z",
     "shell.execute_reply": "2022-12-11T15:12:30.597952Z"
    },
    "papermill": {
     "duration": 254.011868,
     "end_time": "2022-12-11T15:12:30.606508",
     "exception": false,
     "start_time": "2022-12-11T15:08:16.594640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/ao/quantization/fake_quantize.py:325: UserWarning: _aminmax is deprecated as of PyTorch 1.11 and will be removed in a future release. Use aminmax instead. This warning will only appear once per process. (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/ReduceAllOps.cpp:30.)\n",
      "  self.is_symmetric_quant,\n",
      "/opt/conda/lib/python3.7/site-packages/torch/ao/quantization/fake_quantize.py:325: UserWarning: _aminmax is deprecated as of PyTorch 1.11 and will be removed in a future release. Use aminmax instead. This warning will only appear once per process. (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/TensorCompare.cpp:481.)\n",
      "  self.is_symmetric_quant,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 2.427\n",
      "[2] loss: 2.303\n",
      "[3] loss: 2.303\n",
      "[4] loss: 2.303\n",
      "[5] loss: 2.303\n",
      "[6] loss: 2.303\n",
      "[7] loss: 2.303\n",
      "[8] loss: 2.303\n",
      "[9] loss: 2.303\n",
      "[10] loss: 2.303\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "# Training_loop(model_fp32_prepared)\n",
    "train_model(\n",
    "    model=model_fp32_prepared,\n",
    "    criterion=torch.nn.CrossEntropyLoss(),\n",
    "    optimizer=optim.Adam(params=model_fp32_prepared.parameters(), lr=0.001),\n",
    "    trainloader=trainloader,\n",
    "    number_of_epochs=10,\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a1391f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:12:30.621920Z",
     "iopub.status.busy": "2022-12-11T15:12:30.620827Z",
     "iopub.status.idle": "2022-12-11T15:12:30.726846Z",
     "shell.execute_reply": "2022-12-11T15:12:30.725722Z"
    },
    "papermill": {
     "duration": 0.116387,
     "end_time": "2022-12-11T15:12:30.729472",
     "exception": false,
     "start_time": "2022-12-11T15:12:30.613085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the observed model to a quantized model. This does several things:\n",
    "# quantizes the weights, computes and stores the scale and bias value to be\n",
    "# used with each activation tensor, fuses modules where appropriate,\n",
    "# and replaces key operators with quantized implementations.\n",
    "\n",
    "model_fp32_prepared = model_fp32_prepared.to('cpu')\n",
    "model_fp32_prepared.eval()\n",
    "model_int8 = torch.quantization.convert(model_fp32_prepared)\n",
    "\n",
    "# run the model, relevant calculations will happen in int8\n",
    "# res = model_int8(input_fp32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d686045",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:12:30.744165Z",
     "iopub.status.busy": "2022-12-11T15:12:30.743833Z",
     "iopub.status.idle": "2022-12-11T15:12:39.169201Z",
     "shell.execute_reply": "2022-12-11T15:12:39.166785Z"
    },
    "papermill": {
     "duration": 8.4362,
     "end_time": "2022-12-11T15:12:39.172566",
     "exception": false,
     "start_time": "2022-12-11T15:12:30.736366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 10.0%\n"
     ]
    }
   ],
   "source": [
    "# This function crashed Google Colab (because of calculation on cuda in testing function)\n",
    "test_model(\n",
    "    model=model_int8, \n",
    "    dataloader=testloader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78238554",
   "metadata": {
    "papermill": {
     "duration": 0.006038,
     "end_time": "2022-12-11T15:12:39.185294",
     "exception": false,
     "start_time": "2022-12-11T15:12:39.179256",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Size of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6ac602e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:12:39.199622Z",
     "iopub.status.busy": "2022-12-11T15:12:39.198427Z",
     "iopub.status.idle": "2022-12-11T15:12:39.205065Z",
     "shell.execute_reply": "2022-12-11T15:12:39.203943Z"
    },
    "papermill": {
     "duration": 0.016588,
     "end_time": "2022-12-11T15:12:39.207915",
     "exception": false,
     "start_time": "2022-12-11T15:12:39.191327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of basic model: model size: 4212.266KB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size of basic model: {model_size(model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30efaa69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:12:39.221919Z",
     "iopub.status.busy": "2022-12-11T15:12:39.221647Z",
     "iopub.status.idle": "2022-12-11T15:12:39.226845Z",
     "shell.execute_reply": "2022-12-11T15:12:39.225705Z"
    },
    "papermill": {
     "duration": 0.016295,
     "end_time": "2022-12-11T15:12:39.230632",
     "exception": false,
     "start_time": "2022-12-11T15:12:39.214337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of quantized model: model size: 0.012KB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size of quantized model: {model_size(model_int8)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5179869a",
   "metadata": {
    "papermill": {
     "duration": 0.006296,
     "end_time": "2022-12-11T15:12:39.243401",
     "exception": false,
     "start_time": "2022-12-11T15:12:39.237105",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predict one random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "455ad404",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:12:39.257184Z",
     "iopub.status.busy": "2022-12-11T15:12:39.256900Z",
     "iopub.status.idle": "2022-12-11T15:12:39.269854Z",
     "shell.execute_reply": "2022-12-11T15:12:39.268669Z"
    },
    "papermill": {
     "duration": 0.022495,
     "end_time": "2022-12-11T15:12:39.272230",
     "exception": false,
     "start_time": "2022-12-11T15:12:39.249735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answer: 9, Predicted: 3\n"
     ]
    }
   ],
   "source": [
    "index = int(torch.randint(low=0, high=10000, size=(1,)))\n",
    "x, y_true = test_dataset[index]\n",
    "x = x.reshape([28, 28])\n",
    "\n",
    "print(f\"Correct answer: {y_true}, Predicted: {make_prediction(model_int8, x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99929e95",
   "metadata": {
    "papermill": {
     "duration": 0.006024,
     "end_time": "2022-12-11T15:12:39.284373",
     "exception": false,
     "start_time": "2022-12-11T15:12:39.278349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e4ff89f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T15:12:39.298894Z",
     "iopub.status.busy": "2022-12-11T15:12:39.298614Z",
     "iopub.status.idle": "2022-12-11T15:12:39.332051Z",
     "shell.execute_reply": "2022-12-11T15:12:39.331008Z"
    },
    "papermill": {
     "duration": 0.043156,
     "end_time": "2022-12-11T15:12:39.334284",
     "exception": false,
     "start_time": "2022-12-11T15:12:39.291128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), \"model_params.pt\")\n",
    "torch.save(model_int8.state_dict(), \"model_int8_params.pt\")\n",
    "\n",
    "# Load model\n",
    "# model = ConvNet()\n",
    "# model.load_state_dict(torch.load(\"model_params.pt\"))\n",
    "# model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 553.447192,
   "end_time": "2022-12-11T15:12:42.756970",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-11T15:03:29.309778",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "06ccae51b3504b39878ec13ccf8bcd10": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "27ee929dc31a40ee8da2465f6a1015e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "473ed46e05324c2f9b38ecdef53327eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6f0f603ea1624ba3a6701e56cc341576",
       "placeholder": "​",
       "style": "IPY_MODEL_8f73cbf943984265871b74f9f2658874",
       "value": ""
      }
     },
     "534fb54fb37b4e4caa56d2f6b374de23": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_473ed46e05324c2f9b38ecdef53327eb",
        "IPY_MODEL_f77c42254c224611bbab98de327ad457",
        "IPY_MODEL_c467850d361349f18f3e9dfab91bb61e"
       ],
       "layout": "IPY_MODEL_06ccae51b3504b39878ec13ccf8bcd10"
      }
     },
     "6f0f603ea1624ba3a6701e56cc341576": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8f73cbf943984265871b74f9f2658874": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "af9fe2268040432c9f3c4fa603314043": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c467850d361349f18f3e9dfab91bb61e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ecff4539e9fa49b18c04c5095fdf90a2",
       "placeholder": "​",
       "style": "IPY_MODEL_af9fe2268040432c9f3c4fa603314043",
       "value": " 561754112/? [00:05&lt;00:00, 97678296.52it/s]"
      }
     },
     "ea06560f0b0a4d8689549d6bfd102a58": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ecff4539e9fa49b18c04c5095fdf90a2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f77c42254c224611bbab98de327ad457": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ea06560f0b0a4d8689549d6bfd102a58",
       "max": 561753746.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_27ee929dc31a40ee8da2465f6a1015e8",
       "value": 561753746.0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
